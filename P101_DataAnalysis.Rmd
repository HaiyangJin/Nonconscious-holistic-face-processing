---
title: "Data Analysis for P101"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date:  "`r format(Sys.time(), '%d-%m-%Y')`"
knit: ""
output: 
  html_document:
      df_print: paged
      number_sections: true
      toc: true
      toc_depth: 4
      toc_float: true
      includes:
          after_body: Utilities/footer.html
version: "5.0"
---

```{r setup, include=FALSE}
## set chunk options
knitr::opts_chunk$set(echo = TRUE)
```

# Preparations
```{r load the related libraries, message=FALSE}
## load libraries
library(magrittr)
library(tidyverse)

# folder names
folder.data <- "data"
folder.nesi <- "NeSI"
folder.output <- "output"
folder.R <- "R"
folder.uti <- "Utilities"
folder.standard <- "standard_design_analysis" 
folder.multiple <- "multiple_data"

# do you want save the data into *.csv files
# saveData = TRUE
saveData = FALSE

rm.Count.rate <- 0.8
rm.RT <- 0.2

```

This is the data analysis for all the four experiments. At first, the data analysis were conducted separately for each experiment. Next, the data of four experiments were analyzed together.

```{r include=FALSE}
# load R files in the R folder
sapply(list.files(folder.R, "*.R", full.names = TRUE, recursive = TRUE), source)

```

```{r name the levels of variables}
# name the levels of variables
viewing.levels <- c("CFS", "monocular", "CatchOnly")
trialtype.levels <- c("CF", "catch")
congruency.levels <- c("congruent", "incongruent")
alignment.levels <- c("aligned", "misaligned")
sameDifferent.levels <- c("same", "different")
facegroups <- c(paste0("F", 1:5), paste0("M", 1:5))

```


# Experiment 1
```{r information about the data set in E1}
## the filename of the raw data file 
fn.raw.E1 <- file.path(folder.data, "E104_106_n-20_2017-05-04-1446.csv")

## input the filename of the output file (.csv)
output.name <- "E1_104_106"

```

```{r save CSV, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
}

```

The raw data for Experiment 1 was loaded from the file named `r basename(fn.raw.E1)` in the *`r dirname(fn.raw.E1)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E1), message = FALSE}
# read data file
df.raw.E1 <- read_csv(fn.raw.E1)
str(df.raw.E1)
```


```{r calculate the Z value for RT and clean data (E1)}
# clean and rename the levels of independent variables
df.clean.E1 <- {
  df.raw.E1 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "104_CF_CFS" ~ viewing.levels[1],
        Experiment == "106_CF_Mono" ~ viewing.levels[2]
      ),
      TrialType = trialtype.levels[1],
      ExpCode = "E1",
      WithCatch = FALSE,
      Response = thisResponse
    ) %>% 
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    mutate(
      reactionTime = reactionTime + .3, # reaction times starts at the onset of test faces
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup() %>%  # ungroup the data
    mutate(Stimuli = paste(StudyUpper, StudyLower, TargetUpper, TargetLower, sep = "-"))
}

# head(df.clean.E1)
```


## The composite face task
```{r data frame for CF in E1}
df.clean.cf.E1 <- {
  df.clean.E1 %>% 
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E1)
```

```{r check the number of remaining trials E1}
# number of trials in each condition
d.Count.E1 <- {
  df.clean.cf.E1 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.E1 %>%
  spread(Conditions, Count)

rm.count.E1 <- {
  d.Count.E1 %>% 
    filter(Count < max(d.Count.E1$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E1` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.


### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E1)}
# calculate the d'
d.R.E1 <- { # get the hit and correct rejection rates
  df.clean.cf.E1 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>%  # remove Count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E1 <- unique(d.R.E1$Participant[(d.R.E1$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E1 <- unique(d.R.E1$Participant[is.na(d.R.E1$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E1)
rm.E1 <- factor(rmLevels[c(rm.count.E1, rm.nega.E1, rm.missing.E1)], levels = rmLevels)

d.R.E1 <- d.R.E1[!(d.R.E1$Participant %in% rm.E1), ]

# descriptive statistics of d for plotting
desc.d.R.E1 <- {
  d.R.E1 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E1 <- {
  d.R.E1 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```

```{r save data of E1 for analysis in jamovi E1}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E1, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E1, output.d.SPSS, row.names = FALSE)
}
```


#### RainClound plots of d'
```{r rainclound plot of sensitivity E1, warning=FALSE}
knitr::kable(desc.d.R.E1, digits = 4)

d.RainPlot.E1 <- {
  ggplot(data = d.R.E1, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E1, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E1, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 1", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E1}
d.RainPlot.E1
```


#### Line plots of d'
```{r Plot of d E1}

d.ColuPlot.E1 = {
  ggplot(data = desc.d.R.E1, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 1", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E1
```



### Correct response times
```{r calculate the correct response times for R analysis E1}
rt.R.E1 <- {
  df.clean.cf.E1 %>%
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000 + 300, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
desc.rt.R.E1 <- {
  rt.R.E1 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
rt.SPSS.E1 <- {
  rt.R.E1 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```

```{r # save the RT for R analysis for jamovi E1}
# save the RT for R analysis
if (saveData) {
  write.csv(rt.SPSS.E1, output.rt.SPSS, row.names = FALSE)
}
```


#### RainClound plots of RT
```{r rainclound plot of correct response times E1, warning = FALSE}
knitr::kable(desc.rt.R.E1, digits = 4)

rt.RainPlot.E1 <- {
  ggplot(data = rt.R.E1, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.rt.R.E1, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.rt.R.E1, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for E1", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```


&nbsp;

```{r display the RainCloud plot for response times E1}
rt.RainPlot.E1
```


#### Line plots of RT
```{r Plot of correct response times E1}

rt.ColuPlot.E1 = {
  ggplot(data = desc.rt.R.E1, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 1", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("*", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E1
```

### Accuracy (the standard design)
```{r E1 the standard design}

df.scf.E1 <- {
  df.clean.cf.E1 %>% 
    filter(Congruency == "incongruent", SameDifferent == "same", !(Participant %in% rm.E1))
}


acc.R.E1 <- {
  df.scf.E1 %>% 
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

desc.acc.R.E1 <- {
  acc.R.E1 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

acc.SPSS.E1 <- {
  acc.R.E1 %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    select(Participant, Conditions, Accuracy) %>% 
    spread(Conditions, Accuracy)
}

if (saveData) {
  output.acc.SPSS <- file.path(folder.output, folder.standard, paste0(output.name, "_acc_SPSS.csv"))
  write.csv(acc.SPSS.E1, output.acc.SPSS, row.names = FALSE)
}

```

#### RainClound plots of Accuracy
```{r rainclound plot of accuracy E1, warning = FALSE}
knitr::kable(desc.acc.R.E1, digits = 4)

acc.RainPlot.E1 <- {
  ggplot(data = acc.R.E1, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = Accuracy), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.acc.R.E1, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.acc.R.E1, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy (Standard Design) for E1", x = "Alignment", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```


```{r}
acc.RainPlot.E1
```

#### Column plots of accuracy
```{r Plot of acc E1}

acc.ColuPlot.E1 = {
  ggplot(data = desc.acc.R.E1, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0.5, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy (Standard Design) for Experiment 1", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "**", ""), color = "red", size = 6, nudge_y = 0.15, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

acc.ColuPlot.E1
```

## Demographic information
```{r}
# demographic information for E1
demo.E1 <- {
  df.clean.E1 %>% 
    filter(!(Participant %in% rm.E1)) %>% 
    select()
             
  
}
```

# Experiment 2
```{r information about the data set in E2}
## the filename of the raw data file 
fn.raw.E2 <- file.path(folder.data, "E1082_n-34_exp-3_2018-04-17-1639.csv")

## input the filename of the output file (.csv)
output.name <- "E2_1082"

```

```{r save CSV E2, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
  # output.catch.acc.R <- file.path(folder.output, paste0(output.name, "_catch_acc_R.csv"))
  output.catch.acc.SPSS <- file.path(folder.output, paste0(output.name, "_catch_acc_SPSS.csv"))
  # output.catch.rt.R <- file.path(folder.output, paste0(output.name, "_catch_rt_R.csv"))
  output.catch.rt.SPSS <- file.path(folder.output, paste0(output.name, "_catch_rt_SPSS.csv"))
}

```

The raw data for Experiment 2 was loaded from the file named `r basename(fn.raw.E2)` in the *`r dirname(fn.raw.E2)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E2), message = FALSE}
# read data file
df.raw.E2 <- read_csv(fn.raw.E2)
str(df.raw.E2)
```


```{r calculate the Z value for RT and clean data (E2)}
# clean and rename the levels of independent variables
df.clean.E2 <- {
  df.raw.E2 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "10802_CF_CFS_Catch_identity" ~ viewing.levels[1],
        Experiment == "10802_CF_CFS_mono_identity" ~ viewing.levels[2],
        Experiment == "10802_Mono_Catch_identity" ~ viewing.levels[3]
      ),
      TrialType = case_when(
        Condition == "Complete" ~ trialtype.levels[1],
        Condition == "CatchOnly" ~ trialtype.levels[2]
      ),
      ExpCode = "E2",
      WithCatch = TRUE,
      Response = thisResponse,
      FaceGroup = if_else(FaceGroup %in% as.character(1:10), facegroups[FaceGroup], FaceGroup)
    ) %>% 
    group_by(Viewing, Participant, TrialType, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    filter(reactionTime > rm.RT) %>% 
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup() %>%  # ungroup the data 
    mutate(Stimuli = paste(StudyUpper, StudyLower, TargetLower1, TargetLower2, sep = "-"))
}

# head(df.clean.E2)
```
`r nrow(df.raw.E2)-nrow(df.clean.E2)` trials were removed due to shorter than `r rm.RT` ms. 

## The composite face task
```{r data frame for CF in E2}
df.clean.cf.E2 <- {
  df.clean.E2 %>% 
    filter(TrialType == "CF") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E2)
```


```{r check the number of remaining trials E2 cf}
# number of trials in each condition
d.Count.cf.E2 <- {
  df.clean.cf.E2 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.cf.E2 %>%
  spread(Conditions, Count)

rm.count.E2 <- {
  d.Count.cf.E2 %>% 
    filter(Count < max(d.Count.cf.E2$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E2` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.


### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E2)}
# calculate the d'
d.R.E2 <- { # get the hit and correct rejection rates
  df.clean.cf.E2 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>% # remove the count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E2 <- unique(d.R.E2$Participant[(d.R.E2$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E2 <- unique(d.R.E2$Participant[is.na(d.R.E2$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E2)
rm.E2 <- factor(rmLevels[c(rm.count.E2, rm.nega.E2, rm.missing.E2)], levels = rmLevels)

d.R.E2 <- d.R.E2[!(d.R.E2$Participant %in% rm.E2), ]

# descriptive statistics of d for plotting
desc.d.R.E2 <- {
  d.R.E2 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E2 <- {
  d.R.E2 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```
Participant `r rm.nega.E2` were removed due to at least one of their dprime was not larger than 0.


```{r save data of E2 for analysis in jamovi E2}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E2, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E2, output.d.SPSS, row.names = FALSE)
}
```


#### RainClound plots of d'
```{r rainclound plot of sensitivity E2, warning=FALSE}
knitr::kable(desc.d.R.E2, digits = 4)

d.RainPlot.E2 <- {
  ggplot(data = d.R.E2, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E2, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 2", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme 
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E2}
d.RainPlot.E2
```


#### Line plots of d'
```{r Plot of d E2}

d.ColuPlot.E2 = {
  ggplot(data = desc.d.R.E2, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 2", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E2
```



### Correct response times
```{r calculate the correct response times for R analysis E2}
cf.rt.R.E2 <- {
  df.clean.cf.E2 %>%
    filter(!(Participant %in% rm.E2)) %>%  # remove participants
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
cf.desc.rt.R.E2 <- {
  cf.rt.R.E2 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
cf.rt.SPSS.E2 <- {
  cf.rt.R.E2 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```


```{r save the RT for R analysis in jomovi E2}
# save the RT for R analysis
if (saveData) {
  # write.csv(cf.rt.R.E2, output.rt.R, row.names = FALSE)
  write.csv(cf.rt.SPSS.E2, output.rt.SPSS, row.names = FALSE)
}

```


#### RainClound plots of RT
```{r rainclound plot of correct response times E2, warning = FALSE}
knitr::kable(cf.desc.rt.R.E2, digits = 4)

rt.RainPlot.E2 <- {
  ggplot(data = cf.rt.R.E2, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = cf.desc.rt.R.E2, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = cf.desc.rt.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for Experiment 2", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r display the RainCloud plot for response times E2}
rt.RainPlot.E2
```

#### Line plots of RT
```{r Plot of correct response times E2}

rt.ColuPlot.E2 = {
  ggplot(data = cf.desc.rt.R.E2, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 2", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E2
```

### Accuracy (the standard design)
```{r E2 the standard design}

df.scf.E2 <- {
  df.clean.cf.E2 %>% 
    filter(Congruency == "incongruent", SameDifferent == "same", !(Participant %in% rm.E2))
}


acc.R.E2 <- {
  df.scf.E2 %>% 
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

desc.acc.R.E2 <- {
  acc.R.E2 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

acc.SPSS.E2 <- {
  acc.R.E2 %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    select(Participant, Conditions, Accuracy) %>% 
    spread(Conditions, Accuracy)
}



if (saveData) {
  output.acc.SPSS <- file.path(folder.output, folder.standard, paste0(output.name, "_acc_SPSS.csv"))
  write.csv(acc.SPSS.E2, output.acc.SPSS, row.names = FALSE)
  
  acc.E1.E2 <- rbind(acc.SPSS.E1, acc.SPSS.E2)
  output.acc.SPSS <- file.path(folder.output, folder.multiple, "E1_E2_acc_SPSS.csv")
  write.csv(acc.E1.E2, output.acc.SPSS, row.names = FALSE)
}

```

#### RainClound plots of Accuracy
```{r rainclound plot of accuracy E2, warning = FALSE}
knitr::kable(desc.acc.R.E2, digits = 4)

acc.RainPlot.E2 <- {
  ggplot(data = acc.R.E2, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = Accuracy), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.acc.R.E2, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.acc.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy (Standard Design) for E2", x = "Alignment", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```


```{r}
acc.RainPlot.E2
```

#### Column plots of accuracy
```{r Plot of acc E2}

acc.ColuPlot.E2 = {
  ggplot(data = desc.acc.R.E2, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0.5, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy (Standard Design) for Experiment 1", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "***", ""), color = "red", size = 6, nudge_y = 0.15, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

acc.ColuPlot.E2
```


## Catch trials
```{r data frame for Cacth trials in E2}
df.clean.catch.E2 <- {
  df.clean.E2 %>% 
    filter(TrialType == "catch") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2], "CatchOnly" = viewing.levels[3]),
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2])
    ) %>% 
    filter(!(Participant %in% rm.E2))  # remove participants
}

head(df.clean.catch.E2)
```


```{r check the number of remaining trials E2 catch}
# number of trials in each condition
d.Count.catch.E2 <- {
  df.clean.catch.E2 %>%
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.catch.E2 %>%
  spread(Conditions, Count)

```


### Accuracy for catch trials
```{r accuracy for catch trials E2}
catch.acc.R.E2 <- {
  df.clean.catch.E2 %>%
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

catch.desc.acc.R.E2 <- {
  catch.acc.R.E2 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

catch.acc.SPSS.E2 <- {
  catch.acc.R.E2 %>% 
    mutate(Condition = factor(paste(Viewing, Alignment, sep = "."), levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>% 
    select(Participant, Condition, Accuracy) %>%
    spread(Condition, Accuracy)
}


```

```{r save the acc of catch trials in jamovi E2}
# save the acc of catch trials in jamovi E2
if (saveData) {
  # write.csv(catch.acc.R.E2, output.catch.acc.R, row.names = FALSE)
  write.csv(catch.acc.SPSS.E2, output.catch.acc.SPSS, row.names = FALSE)
}
```


#### RainClound plot of accuracy
```{r rainclound plot of accuracy for catch E2, warning=FALSE}
knitr::kable(catch.desc.acc.R.E2, digits = 4)

catch.acc.RainPlot.E2 <- {
  ggplot(data = catch.acc.R.E2, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15, height = 0), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.acc.R.E2, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.acc.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy for Catch Trials in Experiment 2", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r rainclound plot of accuracy for catch trials E2}
catch.acc.RainPlot.E2
```


#### Column plots of accuracy
```{r Plot of accuracy for catch trials E2}

catch.acc.ColuPlot.E2 = {
  ggplot(data = catch.desc.acc.R.E2, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 2", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "***", "***"), color = "red", size = 6, nudge_y = 0.1, nudge_x = 0) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E2
```

### Correct response times
```{r calculate the correct response times of catch trials for R analysis E2}
catch.rt.R.E2 <- {
  df.clean.catch.E2 %>%
    filter(Condition == "CatchOnly") %>% 
    filter(reactionTime <= 10) %>%  # remove the response times which are longer than 10s
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    # filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}


# descriptive statistics of RT for plotting
catch.desc.rt.R.E2 <- {
  catch.rt.R.E2 %>% 
    select(-Count) %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
catch.rt.SPSS.E2 <- {
  catch.rt.R.E2 %>%
    mutate(Conditions = factor(paste(Viewing, Alignment, sep = ".") , levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```

```{r save the RT for R analysis catch trials in E2}
# save the RT for R analysis
if (saveData) {
  # write.csv(catch.rt.R.E2, output.catch.rt.R, row.names = FALSE)
  write.csv(catch.rt.SPSS.E2, output.catch.rt.SPSS, row.names = FALSE)
}
```


#### RainClound plot of response times
```{r rainclound plot of response times for catch trials E2, warning=FALSE}
knitr::kable(catch.desc.rt.R.E2, digits = 4)

catch.rt.RainPlot.E2 <- {
  ggplot(data = catch.rt.R.E2, aes(y = RT, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.rt.R.E2, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.rt.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times of Catch Trials for Experiment 2", x = "Alignment", y = "Response Times (ms)") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot of response times for catch trials E2}
catch.rt.RainPlot.E2
```

#### Column plot of response times
```{r Plot of response times for catch trials E2}

catch.acc.ColuPlot.E2 = {
  ggplot(data = catch.desc.rt.R.E2, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 3200)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 2", x = "Viewing Conditions", y = "Response Times (ms)") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    # geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E2
```

# Experiment 3
```{r information about the data set in E3}
## the filename of the raw data file 
fn.raw.E3 <- file.path(folder.data, "E111_n-22_exp-2_2019-02-25-1437.csv")

## input the filename of the output file (.csv)
output.name <- "E3_111"

```

```{r save CSV E3, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
}

```

The raw data for Experiment 3 was loaded from the file named `r basename(fn.raw.E3)` in the *`r dirname(fn.raw.E3)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E3), message = FALSE}
# read data file
df.raw.E3 <- read_csv(fn.raw.E3)
str(df.raw.E3)
```

```{r calculate the Z value for RT and clean data (E3)}
# clean and rename the levels of independent variables
df.clean.E3 <- {
  df.raw.E3 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "111_CF_CFS_test" ~ viewing.levels[1],
        Experiment == "111_CF_monocular_test" ~ viewing.levels[2]
      ),
      TrialType = trialtype.levels[1],
      ExpCode = "E3",
      WithCatch = FALSE,
      Response = substring("SD", thisResponse, thisResponse),
      thisResponse = as.character(thisResponse)
    ) %>% 
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    filter(reactionTime > rm.RT) %>% # only keep response longer than 200ms
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup() %>%  # ungroup the data
    mutate(Stimuli = paste(StudyUpper, StudyLower, TargetUpper, TargetLower, sep = "-"))
}

# head(df.clean.E3)
```
`r nrow(df.raw.E3)-nrow(df.clean.E3)` trials were removed due to shorter than `r rm.RT` ms. 

## The composite face task
```{r data frame for CF in E3}
df.clean.cf.E3 <- {
  df.clean.E3 %>% 
    # filter(TrialType == "CF") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E3)
```

```{r check the number of remaining trials E3}
# number of trials in each condition
d.Count.E3 <- {
  df.clean.cf.E3 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.E3 %>%
  spread(Conditions, Count)

rm.count.E3 <- {
  d.Count.E3 %>% 
    filter(Count < max(d.Count.E3$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E3` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.


### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E3)}
# calculate the d'
d.R.E3 <- { # get the hit and correct rejection rates
  df.clean.cf.E3 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>%  # remove Count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E3 <- unique(d.R.E3$Participant[(d.R.E3$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E3 <- unique(d.R.E3$Participant[is.na(d.R.E3$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E3)
rm.E3 <- factor(rmLevels[unique(c(rm.count.E3, rm.nega.E3, rm.missing.E3))], levels = rmLevels)

d.R.E3 <- d.R.E3[!(d.R.E3$Participant %in% rm.E3), ]

# descriptive statistics of d for plotting
desc.d.R.E3 <- {
  d.R.E3 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E3 <- {
  d.R.E3 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```

Participant `r rm.nega.E3` were removed due to at least one of their dprime was not larger than 0.


```{r save data of E3 for analysis in jamovi E3}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E3, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E3, output.d.SPSS, row.names = FALSE)
}
```

#### RainClound plots of d'
```{r rainclound plot of sensitivity E3, warning=FALSE}
knitr::kable(desc.d.R.E3, digits = 4)

d.RainPlot.E3 <- {
  ggplot(data = d.R.E3, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E3, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E3, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 3", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme 
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E3}
d.RainPlot.E3
```

#### Line plots of d'
```{r Plot of d E3}

d.ColuPlot.E3 = {
  ggplot(data = desc.d.R.E3, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 3", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E3
```



### Correct response times
```{r calculate the correct response times for R analysis E3}
cf.rt.R.E3 <- {
  df.clean.cf.E3 %>%
    filter(!(Participant %in% rm.E3)) %>%  # remove participants
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
cf.desc.rt.R.E3 <- {
  cf.rt.R.E3 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
cf.rt.SPSS.E3 <- {
  cf.rt.R.E3 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```


```{r save the RT for R analysis in jomovi E3}
# save the RT for R analysis
if (saveData) {
  # write.csv(cf.rt.R.E3, output.rt.R, row.names = FALSE)
  write.csv(cf.rt.SPSS.E3, output.rt.SPSS, row.names = FALSE)
}

```

#### RainClound plots of RT
```{r rainclound plot of correct response times E3, warning = FALSE}
knitr::kable(cf.desc.rt.R.E3, digits = 4)

rt.RainPlot.E3 <- {
  ggplot(data = cf.rt.R.E3, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = cf.desc.rt.R.E3, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = cf.desc.rt.R.E3, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for Experiment 3", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r display the RainCloud plot for response times E3}
rt.RainPlot.E3
```

#### Line plots of RT
```{r Plot of correct response times E3}

rt.ColuPlot.E3 = {
  ggplot(data = cf.desc.rt.R.E3, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 3", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E3
```


### Accuracy (the standard design)
```{r E3 the standard design}

df.scf.E3 <- {
  df.clean.cf.E3 %>% 
    filter(Congruency == "incongruent", SameDifferent == "same", !(Participant %in% rm.E3))
}


acc.R.E3 <- {
  df.scf.E3 %>% 
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

desc.acc.R.E3 <- {
  acc.R.E3 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

acc.SPSS.E3 <- {
  acc.R.E3 %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    select(Participant, Conditions, Accuracy) %>% 
    spread(Conditions, Accuracy)
}

if (saveData) {
  output.acc.SPSS <- file.path(folder.output, folder.standard, paste0(output.name, "_acc_SPSS.csv"))
  write.csv(acc.SPSS.E3, output.acc.SPSS, row.names = FALSE)
}

```

#### RainClound plots of Accuracy
```{r rainclound plot of accuracy E3, warning = FALSE}
knitr::kable(desc.acc.R.E3, digits = 4)

acc.RainPlot.E3 <- {
  ggplot(data = acc.R.E3, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = Accuracy), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.acc.R.E3, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.acc.R.E3, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy (Standard Design) for E3", x = "Alignment", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```


```{r}
acc.RainPlot.E3
```

#### Column plots of accuracy
```{r Plot of acc E3}

acc.ColuPlot.E3 = {
  ggplot(data = desc.acc.R.E3, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0.5, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy (Standard Design) for Experiment 1", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "**", ""), color = "red", size = 6, nudge_y = 0.15, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

acc.ColuPlot.E3
```


# Experiment 4
```{r information about the data set in E4}
## the filename of the raw data file 
fn.raw.E4 <- file.path(folder.data, "E112_n-31_exp-3_2019-04-02-1609.csv")

## input the filename of the output file (.csv)
output.name <- "E4_112"

```

```{r save CSV E4, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
  # output.catch.acc.R <- file.path(folder.output, paste0(output.name, "_catch_acc_R.csv"))
  output.catch.acc.SPSS <- file.path(folder.output, paste0(output.name, "_catch_acc_SPSS.csv"))
  # output.catch.rt.R <- file.path(folder.output, paste0(output.name, "_catch_rt_R.csv"))
  output.catch.rt.SPSS <- file.path(folder.output, paste0(output.name, "_catch_rt_SPSS.csv"))
}

```

The raw data for Experiment 4 was loaded from the file named `r basename(fn.raw.E4)` in the *`r dirname(fn.raw.E4)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E4), message = FALSE}
# read data file
df.raw.E4 <- read_csv(fn.raw.E4)
str(df.raw.E4)
```


```{r calculate the Z value for RT and clean data (E4)}
# clean and rename the levels of independent variables
df.clean.E4 <- {
  df.raw.E4 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "112_CF_CFS_catch_test" ~ viewing.levels[1],
        Experiment == "112_CF_monocular_catch_test" ~ viewing.levels[2],
        Experiment == "112_catch_test" ~ viewing.levels[3]
      ),
      TrialType = case_when(
        TrialType == "CF" ~ trialtype.levels[1],
        TrialType == "Catch" ~ trialtype.levels[2]
      ),
      ExpCode = "E4",
      WithCatch = TRUE,
      Response = if_else(TrialType == "CF", substring("SD", thisResponse, thisResponse), as.character(thisResponse)),
      thisResponse = as.character(thisResponse)
    ) %>% 
    group_by(Viewing, Participant, TrialType, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    filter(reactionTime > rm.RT) %>% # only keep response longer than 200ms
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup() %>%  # ungroup the data
    mutate(Stimuli = paste(StudyUpper, StudyLower, TargetUpper, TargetLower, sep = "-"))
}

# head(df.clean.E4)
```
`r nrow(df.raw.E4)-nrow(df.clean.E4)` trials were removed due to shorter than `r rm.RT` ms. 

## The composite face task
```{r data frame for CF in E4}
df.clean.cf.E4 <- {
  df.clean.E4 %>% 
    filter(TrialType == "CF") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E4)
```

```{r check the number of remaining trials E4 cf}
# number of trials in each condition
d.Count.cf.E4 <- {
  df.clean.cf.E4 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.cf.E4 %>%
  spread(Conditions, Count)

rm.count.E4 <- {
  d.Count.cf.E4 %>% 
    filter(Count < max(d.Count.cf.E4$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E4` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.

### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E4)}
# calculate the d'
d.R.E4 <- { # get the hit and correct rejection rates
  df.clean.cf.E4 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>%  # remove Count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E4 <- unique(d.R.E4$Participant[(d.R.E4$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E4 <- unique(d.R.E4$Participant[is.na(d.R.E4$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E4)
rm.E4 <- factor(rmLevels[unique(c(rm.count.E4, rm.nega.E4, rm.missing.E4))], levels = rmLevels)

d.R.E4 <- d.R.E4[!(d.R.E4$Participant %in% rm.E4), ]

# descriptive statistics of d for plotting
desc.d.R.E4 <- {
  d.R.E4 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E4 <- {
  d.R.E4 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```
Participant `r rm.nega.E4` were removed due to at least one of their dprime was not larger than 0.

Participant `r rm.missing.E4` were removed due to at least one of their dprime was missing.


```{r save data of E4 for analysis in jamovi E4}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E4, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E4, output.d.SPSS, row.names = FALSE)
}
```


#### RainClound plots of d'
```{r rainclound plot of sensitivity E4, warning=FALSE}
knitr::kable(desc.d.R.E4, digits = 4)

d.RainPlot.E4 <- {
  ggplot(data = d.R.E4, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E4, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 4", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme 
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E4}
d.RainPlot.E4
```


#### Line plots of d'
```{r Plot of d E4}

d.ColuPlot.E4 = {
  ggplot(data = desc.d.R.E4, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 4", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E4
```



### Correct response times
```{r calculate the correct response times for R analysis E4}
cf.rt.R.E4 <- {
  df.clean.cf.E4 %>%
    filter(!(Participant %in% rm.E4)) %>%  # remove participants
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
cf.desc.rt.R.E4 <- {
  cf.rt.R.E4 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
cf.rt.SPSS.E4 <- {
  cf.rt.R.E4 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```


```{r save the RT for R analysis in jomovi E4}
# save the RT for R analysis
if (saveData) {
  # write.csv(cf.rt.R.E4, output.rt.R, row.names = FALSE)
  write.csv(cf.rt.SPSS.E4, output.rt.SPSS, row.names = FALSE)
}

```


#### RainClound plots of RT
```{r rainclound plot of correct response times E4, warning = FALSE}
knitr::kable(cf.desc.rt.R.E4, digits = 4)

rt.RainPlot.E4 <- {
  ggplot(data = cf.rt.R.E4, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = cf.desc.rt.R.E4, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = cf.desc.rt.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for Experiment 4", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r display the RainCloud plot for response times E4}
rt.RainPlot.E4
```

#### Line plots of RT
```{r Plot of correct response times E4}

rt.ColuPlot.E4 = {
  ggplot(data = cf.desc.rt.R.E4, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 4", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E4
```

### Accuracy (the standard design)
```{r E4 the standard design}

df.scf.E4 <- {
  df.clean.cf.E4 %>% 
    filter(Congruency == "incongruent", SameDifferent == "same", !(Participant %in% rm.E4))
}


acc.R.E4 <- {
  df.scf.E4 %>% 
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

desc.acc.R.E4 <- {
  acc.R.E4 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

acc.SPSS.E4 <- {
  acc.R.E4 %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    select(Participant, Conditions, Accuracy) %>% 
    spread(Conditions, Accuracy)
}

if (saveData) {
  output.acc.SPSS <- file.path(folder.output, folder.standard, paste0(output.name, "_acc_SPSS.csv"))
  write.csv(acc.SPSS.E4, output.acc.SPSS, row.names = FALSE)
  
  acc.E3.E4 <- rbind(acc.SPSS.E3, acc.SPSS.E4)
  output.acc.SPSS <- file.path(folder.output, folder.multiple, "E3_E4_acc_SPSS.csv")
  write.csv(acc.E3.E4, output.acc.SPSS, row.names = FALSE)
}

```

#### RainClound plots of Accuracy
```{r rainclound plot of accuracy E4, warning = FALSE}
knitr::kable(desc.acc.R.E4, digits = 4)

acc.RainPlot.E4 <- {
  ggplot(data = acc.R.E4, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = Accuracy), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.acc.R.E4, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.acc.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy (Standard Design) for E4", x = "Alignment", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```


```{r}
acc.RainPlot.E4
```

#### Column plots of accuracy
```{r Plot of acc E4}

acc.ColuPlot.E4 = {
  ggplot(data = desc.acc.R.E4, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0.5, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy (Standard Design) for Experiment 1", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c(".064", "", "***", ""), color = c("blue", "red", "red", "red"), size = 6, nudge_y = 0.15, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

acc.ColuPlot.E4
```


## Catch trials
```{r data frame for Cacth trials in E4}
df.clean.catch.E4 <- {
  df.clean.E4 %>% 
    filter(TrialType == "catch") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2], "CatchOnly" = viewing.levels[3]),
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2])
    ) %>% 
    filter(!(Participant %in% rm.E4))  # remove participants
}

df.clean.catch.E4
```


```{r check the number of remaining trials E4 catch}
# number of trials in each condition
d.Count.catch.E4 <- {
  df.clean.catch.E4 %>%
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.catch.E4 %>%
  spread(Conditions, Count)

```


### Accuracy for catch trials
```{r accuracy for catch trials E4}
catch.acc.R.E4 <- {
  df.clean.catch.E4 %>%
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

catch.desc.acc.R.E4 <- {
  catch.acc.R.E4 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

catch.acc.SPSS.E4 <- {
  catch.acc.R.E4 %>% 
    mutate(Condition = factor(paste(Viewing, Alignment, sep = "."), levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>% 
    select(Participant, Condition, Accuracy) %>%
    spread(Condition, Accuracy)
}


```

```{r save the acc of catch trials in jamovi E4}
# save the acc of catch trials in jamovi E4
if (saveData) {
  output.acc.SPSS <- file.path(folder.output, folder.standard, paste0(output.name, "_acc_SPSS.csv"))
  write.csv(catch.acc.SPSS.E4, output.catch.acc.SPSS, row.names = FALSE)
}
```


#### RainClound plot of accuracy
```{r rainclound plot of accuracy for catch E4, warning=FALSE}
knitr::kable(catch.desc.acc.R.E4, digits = 4)

catch.acc.RainPlot.E4 <- {
  ggplot(data = catch.acc.R.E4, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15, height = 0), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.acc.R.E4, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.acc.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy for Catch Trials in Experiment 4", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r rainclound plot of accuracy for catch trials E4}
catch.acc.RainPlot.E4
```


#### Column plots of accuracy
```{r Plot of accuracy for catch trials E4}

catch.acc.ColuPlot.E4 = {
  ggplot(data = catch.desc.acc.R.E4, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 4", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "***", "***"), color = "red", size = 6, nudge_y = 0.1, nudge_x = 0) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E4
```

### Response Times
```{r calculate the correct response times of catch trials for R analysis E4}
catch.rt.R.E4 <- {
  df.clean.catch.E4 %>%
    filter(reactionTime <= 10) %>%  # remove the response times which are longer than 10s
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    # filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}


# descriptive statistics of RT for plotting
catch.desc.rt.R.E4 <- {
  catch.rt.R.E4 %>% 
    select(-Count) %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
catch.rt.SPSS.E4 <- {
  catch.rt.R.E4 %>%
    mutate(Conditions = factor(paste(Viewing, Alignment, sep = ".") , levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```

```{r save the RT for R analysis catch trials in E4}
# save the RT for R analysis
if (saveData) {
  # write.csv(catch.rt.R.E4, output.catch.rt.R, row.names = FALSE)
  write.csv(catch.rt.SPSS.E4, output.catch.rt.SPSS, row.names = FALSE)
}
```


#### RainClound plot of response times
```{r rainclound plot of response times for catch trials E4, warning=FALSE}
knitr::kable(catch.desc.rt.R.E4, digits = 4)

catch.rt.RainPlot.E4 <- {
  ggplot(data = catch.rt.R.E4, aes(y = RT, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.rt.R.E4, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.rt.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times of Catch Trials for Experiment 4", x = "Alignment", y = "Response Times (ms)") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot of response times for catch trials E4}
catch.rt.RainPlot.E4
```

#### Column plot of response times
```{r Plot of response times for catch trials E4}

catch.acc.ColuPlot.E4 = {
  ggplot(data = catch.desc.rt.R.E4, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4600)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 4", x = "Viewing Conditions", y = "Response Times (ms)") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    # geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E4
```


# Analysis for all the four experiemnts
```{r load libraries for lmm}
# load libraries for lmm
library(lme4)
library(lmerTest)
library(emmeans)

emm_options(pbkrtest.limit = 1e6, lmerTest.limit = 1e6)

```

```{r combine the data from the four experiments}

df.all <- bind_rows(list(df.clean.E1, df.clean.E2, df.clean.E3, df.clean.E4))
head(df.all)
```

## The composite face task
### Behavioral response
```{r tidy up the dataframe for the composite face task}
rmParticipant <- c(as.character(rm.E1), as.character(rm.E2), as.character(rm.E3), as.character(rm.E4))

df.cf.all <- {
  df.all %>% 
    filter(TrialType == "CF") %>% 
    filter(!(Participant %in% rmParticipant)) %>% 
    mutate(Participant = as.factor(Participant),
           Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
           Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
           Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
           SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2]),
           FaceGroup = as.factor(FaceGroup),
           CFS_Cover = as.factor(if_else(ExpCode %in% c("E1", "E2"), "both", "test")),
           ExpCode = as.factor(ExpCode)) %>% 
    # filter(SameDifferent == "same") %>% # only keep the same trials of the data
    select(Viewing, Participant, Congruency, Alignment, FaceGroup, CFS_Cover, WithCatch, isCorrect, reactionTime, ExpCode, Stimuli, RT.Z)
}

head(df.cf.all)

```


```{r manually set the dummy coding for random effects}
# manually set the dummy coding for random effects
df.cf.all %<>% sdif_coding_P101()  # dummy_coding_P101()

if (saveData) {
  save(df.cf.all, file = file.path(folder.nesi, "P101_cf_clean.RData"))
}
```

Participants `r rmParticipant` were removed due to distinctive reasons.

### Sensitivity d'
```{r}
# combine d' data
d.R.E1 %<>% mutate(ExpCode = "E1", WithCatch = 0, Participant = as.character(Participant))
d.R.E2 %<>% mutate(ExpCode = "E2", WithCatch = 1, Participant = as.character(Participant))
d.R.E3 %<>% mutate(ExpCode = "E3", WithCatch = 0, Participant = as.character(Participant))
d.R.E4 %<>% mutate(ExpCode = "E4", WithCatch = 1, Participant = as.character(Participant))

d.R.all <- {
  bind_rows(d.R.E1, d.R.E2, d.R.E3, d.R.E4) %>% 
    mutate(
      CFS_Cover = as.factor(if_else(ExpCode %in% c("E1", "E2"), "both", "test"))
    )
}

if (saveData) {
  save(d.R.all, file = file.path(folder.nesi, "P101_d_R.RData"))
}

```


```{r}

d.SPSS.all <- {
  d.R.all %>% 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% 
    select(ExpCode, Participant, CFS_Cover, WithCatch, Conditions, dprime) %>% 
    spread(Conditions, dprime)
}


if (saveData) {
  write_csv(d.SPSS.all, file.path(folder.output, folder.multiple, "P101_d_SPSS.csv"))
  write_csv(filter(d.SPSS.all, ExpCode %in% c("E1", "E2")), file.path(folder.output, folder.multiple, "E1_E2_d_SPSS.csv"))
  write_csv(filter(d.SPSS.all, ExpCode %in% c("E3", "E4")), file.path(folder.output, folder.multiple, "E3_E4_d_SPSS.csv"))
}

```

# Versions of Packages Used
```{r versions}
rstudioapi::versionInfo()
sessionInfo()
```

