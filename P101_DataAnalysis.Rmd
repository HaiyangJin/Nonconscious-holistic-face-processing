---
title: "Data Analysis for P101"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date:  "`r format(Sys.time(), '%d-%m-%Y')`"
knit: ""
output: 
  html_document:
      df_print: paged
      number_sections: true
      toc: true
      toc_depth: 4
      toc_float: true
      includes:
          after_body: Utilities/footer.html
version: "5.0"
---

```{r setup, include=FALSE}
## set chunk options
knitr::opts_chunk$set(echo = TRUE)
```

# Preparations
```{r load the related libraries, message=FALSE}
## load libraries
library(magrittr)
library(tidyverse)
library(lme4)
library(lmerTest)
library(emmeans)

# folder names
folder.data <- "data"
folder.nesi <- "NeSI"
folder.output <- "output"
folder.R <- "R"
folder.uti <- "Utilities"

# do you want save the data into *.csv files
saveData = TRUE
# saveData = FALSE

rm.Count.rate <- 0.8
rm.RT <- 0.2

```

This is the data analysis for all the four experiments. At first, the data analysis were conducted separately for each experiment. Next, the data of four experiments were analyzed together.

```{r include=FALSE}
# load R files in the R folder
# source(file.path(folder.R, "geom_flat_violin.R"))
# source(file.path(folder.R, "plot_theme.R"))
# source(file.path(folder.R, "dummy_coding_P101.R"))

sapply(list.files(folder.R, "*.R", full.names = TRUE, recursive = TRUE), source)

```

```{r name the levels of variables}
# name the levels of variables
viewing.levels <- c("CFS", "monocular", "CatchOnly")
trialtype.levels <- c("CF", "catch")
congruency.levels <- c("congruent", "incongruent")
alignment.levels <- c("aligned", "misaligned")
sameDifferent.levels <- c("same", "different")
facegroups <- c(paste0("F", 1:5), paste0("M", 1:5))

```


# Experiment 1
```{r information about the data set in E1}
## the filename of the raw data file 
fn.raw.E1 <- file.path(folder.data, "E104_106_n-20_2017-05-04-1446.csv")

## input the filename of the output file (.csv)
output.name <- "E1_104_106"

```

```{r save CSV, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
}

```

The raw data for Experiment 1 was loaded from the file named `r basename(fn.raw.E1)` in the *`r dirname(fn.raw.E1)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E1), message = FALSE}
# read data file
df.raw.E1 <- read_csv(fn.raw.E1)
str(df.raw.E1)
```


```{r calculate the Z value for RT and clean data (E1)}
# clean and rename the levels of independent variables
df.clean.E1 <- {
  df.raw.E1 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "104_CF_CFS" ~ viewing.levels[1],
        Experiment == "106_CF_Mono" ~ viewing.levels[2]
      ),
      TrialType = trialtype.levels[1],
      ExpCode = "E1",
      WithCatch = FALSE,
      Response = thisResponse
    ) %>% 
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    # mutate(Stimuli = paste(StudyUpper, StudyLower, TargetUpper, TargetLower, sep = "-")) %>%
    ungroup()  # ungroup the data
}

# head(df.clean.E1)
```


## The composite face task
```{r data frame for CF in E1}
df.clean.cf.E1 <- {
  df.clean.E1 %>% 
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E1)
```

```{r check the number of remaining trials E1}
# number of trials in each condition
d.Count.E1 <- {
  df.clean.cf.E1 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.E1 %>%
  spread(Conditions, Count)

rm.count.E1 <- {
  d.Count.E1 %>% 
    filter(Count < max(d.Count.E1$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E1` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.


### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E1)}
# calculate the d'
d.R.E1 <- { # get the hit and correct rejection rates
  df.clean.cf.E1 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>%  # remove Count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E1 <- unique(d.R.E1$Participant[(d.R.E1$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E1 <- unique(d.R.E1$Participant[is.na(d.R.E1$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E1)
rm.E1 <- factor(rmLevels[c(rm.count.E1, rm.nega.E1, rm.missing.E1)], levels = rmLevels)

d.R.E1 <- d.R.E1[!(d.R.E1$Participant %in% rm.E1), ]

# descriptive statistics of d for plotting
desc.d.R.E1 <- {
  d.R.E1 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E1 <- {
  d.R.E1 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```

```{r save data of E1 for analysis in jamovi E1}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E1, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E1, output.d.SPSS, row.names = FALSE)
}
```


#### RainClound plots of d'
```{r rainclound plot of sensitivity E1, warning=FALSE}
knitr::kable(desc.d.R.E1, digits = 4)

d.RainPlot.E1 <- {
  ggplot(data = d.R.E1, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E1, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E1, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 1", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E1}
d.RainPlot.E1
```


#### Line plots of d'
```{r Plot of d E1}

d.ColuPlot.E1 = {
  ggplot(data = desc.d.R.E1, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 1", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E1
```



### Correct response times
```{r calculate the correct response times for R analysis E1}
rt.R.E1 <- {
  df.clean.cf.E1 %>%
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000 + 300, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
desc.rt.R.E1 <- {
  rt.R.E1 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
rt.SPSS.E1 <- {
  rt.R.E1 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```

```{r # save the RT for R analysis for jamovi E1}
# save the RT for R analysis
if (saveData) {
  # write.csv(rt.R.E1, output.rt.R, row.names = FALSE)
  write.csv(rt.SPSS.E1, output.rt.SPSS, row.names = FALSE)
}
```


#### RainClound plots of RT
```{r rainclound plot of correct response times E1, warning = FALSE}
knitr::kable(desc.rt.R.E1, digits = 4)

rt.RainPlot.E1 <- {
  ggplot(data = rt.R.E1, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.rt.R.E1, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.rt.R.E1, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for E1", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```


&nbsp;

```{r display the RainCloud plot for response times E1}
rt.RainPlot.E1
```


#### Line plots of RT
```{r Plot of correct response times E1}

rt.ColuPlot.E1 = {
  ggplot(data = desc.rt.R.E1, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 1", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("*", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E1
```

## Demographic information
```{r}
# demographic information for E1
demo.E1 <- {
  df.clean.E1 %>% 
    filter(!(Participant %in% rm.E1)) %>% 
    select()
             
  
}
```

# Experiment 2
```{r information about the data set in E2}
## the filename of the raw data file 
fn.raw.E2 <- file.path(folder.data, "E1082_n-34_exp-3_2018-04-17-1639.csv")

## input the filename of the output file (.csv)
output.name <- "E2_1082"

```

```{r save CSV E2, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
  # output.catch.acc.R <- file.path(folder.output, paste0(output.name, "_catch_acc_R.csv"))
  output.catch.acc.SPSS <- file.path(folder.output, paste0(output.name, "_catch_acc_SPSS.csv"))
  # output.catch.rt.R <- file.path(folder.output, paste0(output.name, "_catch_rt_R.csv"))
  output.catch.rt.SPSS <- file.path(folder.output, paste0(output.name, "_catch_rt_SPSS.csv"))
}

```

The raw data for Experiment 2 was loaded from the file named `r basename(fn.raw.E2)` in the *`r dirname(fn.raw.E2)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E2), message = FALSE}
# read data file
df.raw.E2 <- read_csv(fn.raw.E2)
str(df.raw.E2)
```


```{r calculate the Z value for RT and clean data (E2)}
# clean and rename the levels of independent variables
df.clean.E2 <- {
  df.raw.E2 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "10802_CF_CFS_Catch_identity" ~ viewing.levels[1],
        Experiment == "10802_CF_CFS_mono_identity" ~ viewing.levels[2],
        Experiment == "10802_Mono_Catch_identity" ~ viewing.levels[3]
      ),
      TrialType = case_when(
        Condition == "Complete" ~ trialtype.levels[1],
        Condition == "CatchOnly" ~ trialtype.levels[2]
      ),
      ExpCode = "E2",
      WithCatch = TRUE,
      Response = thisResponse,
      FaceGroup = if_else(FaceGroup %in% as.character(1:10), facegroups[FaceGroup], FaceGroup)
    ) %>% 
    group_by(Viewing, Participant, TrialType, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    filter(reactionTime > rm.RT) %>% 
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup()  # ungroup the data
}

# head(df.clean.E2)
```


## The composite face task
```{r data frame for CF in E2}
df.clean.cf.E2 <- {
  df.clean.E2 %>% 
    filter(TrialType == "CF") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E2)
```


```{r check the number of remaining trials E2 cf}
# number of trials in each condition
d.Count.cf.E2 <- {
  df.clean.cf.E2 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.cf.E2 %>%
  spread(Conditions, Count)

rm.count.E2 <- {
  d.Count.cf.E2 %>% 
    filter(Count < max(d.Count.cf.E2$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E2` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.


### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E2)}
# calculate the d'
d.R.E2 <- { # get the hit and correct rejection rates
  df.clean.cf.E2 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>% # remove the count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E2 <- unique(d.R.E2$Participant[(d.R.E2$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E2 <- unique(d.R.E2$Participant[is.na(d.R.E2$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E2)
rm.E2 <- factor(rmLevels[c(rm.count.E2, rm.nega.E2, rm.missing.E2)], levels = rmLevels)

d.R.E2 <- d.R.E2[!(d.R.E2$Participant %in% rm.E2), ]

# descriptive statistics of d for plotting
desc.d.R.E2 <- {
  d.R.E2 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E2 <- {
  d.R.E2 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```
Participant `r rm.nega.E2` were removed due to at least one of their dprime was not larger than 0.


```{r save data of E2 for analysis in jamovi E2}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E2, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E2, output.d.SPSS, row.names = FALSE)
}
```


#### RainClound plots of d'
```{r rainclound plot of sensitivity E2, warning=FALSE}
knitr::kable(desc.d.R.E2, digits = 4)

d.RainPlot.E2 <- {
  ggplot(data = d.R.E2, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E2, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 2", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme 
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E2}
d.RainPlot.E2
```


#### Line plots of d'
```{r Plot of d E2}

d.ColuPlot.E2 = {
  ggplot(data = desc.d.R.E2, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 2", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E2
```



### Correct response times
```{r calculate the correct response times for R analysis E2}
cf.rt.R.E2 <- {
  df.clean.cf.E2 %>%
    filter(!(Participant %in% rm.E2)) %>%  # remove participants
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
cf.desc.rt.R.E2 <- {
  cf.rt.R.E2 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
cf.rt.SPSS.E2 <- {
  cf.rt.R.E2 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```


```{r save the RT for R analysis in jomovi E2}
# save the RT for R analysis
if (saveData) {
  # write.csv(cf.rt.R.E2, output.rt.R, row.names = FALSE)
  write.csv(cf.rt.SPSS.E2, output.rt.SPSS, row.names = FALSE)
}

```


#### RainClound plots of RT
```{r rainclound plot of correct response times E2, warning = FALSE}
knitr::kable(cf.desc.rt.R.E2, digits = 4)

rt.RainPlot.E2 <- {
  ggplot(data = cf.rt.R.E2, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = cf.desc.rt.R.E2, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = cf.desc.rt.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for Experiment 2", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r display the RainCloud plot for response times E2}
rt.RainPlot.E2
```

#### Line plots of RT
```{r Plot of correct response times E2}

rt.ColuPlot.E2 = {
  ggplot(data = cf.desc.rt.R.E2, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 2", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E2
```

## Catch trials
```{r data frame for Cacth trials in E2}
df.clean.catch.E2 <- {
  df.clean.E2 %>% 
    filter(TrialType == "catch") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2], "CatchOnly" = viewing.levels[3]),
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2])
    ) %>% 
    filter(!(Participant %in% rm.E2))  # remove participants
}

head(df.clean.catch.E2)
```


```{r check the number of remaining trials E2 catch}
# number of trials in each condition
d.Count.catch.E2 <- {
  df.clean.catch.E2 %>%
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.catch.E2 %>%
  spread(Conditions, Count)

```


### Accuracy for catch trials
```{r accuracy for catch trials E2}
catch.acc.R.E2 <- {
  df.clean.catch.E2 %>%
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

catch.desc.acc.R.E2 <- {
  catch.acc.R.E2 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

catch.acc.SPSS.E2 <- {
  catch.acc.R.E2 %>% 
    mutate(Condition = factor(paste(Viewing, Alignment, sep = "."), levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>% 
    select(Participant, Condition, Accuracy) %>%
    spread(Condition, Accuracy)
}


```

```{r save the acc of catch trials in jamovi E2}
# save the acc of catch trials in jamovi E2
if (saveData) {
  # write.csv(catch.acc.R.E2, output.catch.acc.R, row.names = FALSE)
  write.csv(catch.acc.SPSS.E2, output.catch.acc.SPSS, row.names = FALSE)
}
```


#### RainClound plot of accuracy
```{r rainclound plot of accuracy for catch E2, warning=FALSE}
knitr::kable(catch.desc.acc.R.E2, digits = 4)

catch.acc.RainPlot.E2 <- {
  ggplot(data = catch.acc.R.E2, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15, height = 0), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.acc.R.E2, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.acc.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy for Catch Trials in Experiment 2", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r rainclound plot of accuracy for catch trials E2}
catch.acc.RainPlot.E2
```


#### Column plots of accuracy
```{r Plot of accuracy for catch trials E2}

catch.acc.ColuPlot.E2 = {
  ggplot(data = catch.desc.acc.R.E2, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 2", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "***", "***"), color = "red", size = 6, nudge_y = 0.1, nudge_x = 0) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E2
```

### Correct response times
```{r calculate the correct response times of catch trials for R analysis E2}
catch.rt.R.E2 <- {
  df.clean.catch.E2 %>%
    filter(Condition == "CatchOnly") %>% 
    filter(reactionTime <= 10) %>%  # remove the response times which are longer than 10s
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    # filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}


# descriptive statistics of RT for plotting
catch.desc.rt.R.E2 <- {
  catch.rt.R.E2 %>% 
    select(-Count) %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
catch.rt.SPSS.E2 <- {
  catch.rt.R.E2 %>%
    mutate(Conditions = factor(paste(Viewing, Alignment, sep = ".") , levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```

```{r save the RT for R analysis catch trials in E2}
# save the RT for R analysis
if (saveData) {
  # write.csv(catch.rt.R.E2, output.catch.rt.R, row.names = FALSE)
  write.csv(catch.rt.SPSS.E2, output.catch.rt.SPSS, row.names = FALSE)
}
```


#### RainClound plot of response times
```{r rainclound plot of response times for catch trials E2, warning=FALSE}
knitr::kable(catch.desc.rt.R.E2, digits = 4)

catch.rt.RainPlot.E2 <- {
  ggplot(data = catch.rt.R.E2, aes(y = RT, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.rt.R.E2, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.rt.R.E2, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times of Catch Trials for Experiment 2", x = "Alignment", y = "Response Times (ms)") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot of response times for catch trials E2}
catch.rt.RainPlot.E2
```

#### Column plot of response times
```{r Plot of response times for catch trials E2}

catch.acc.ColuPlot.E2 = {
  ggplot(data = catch.desc.rt.R.E2, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 3200)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 2", x = "Viewing Conditions", y = "Response Times (ms)") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    # geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E2
```

# Experiment 3
```{r information about the data set in E3}
## the filename of the raw data file 
fn.raw.E3 <- file.path(folder.data, "E111_n-22_exp-2_2019-02-25-1437.csv")

## input the filename of the output file (.csv)
output.name <- "E3_111"

```

```{r save CSV E3, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
}

```

The raw data for Experiment 3 was loaded from the file named `r basename(fn.raw.E3)` in the *`r dirname(fn.raw.E3)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E3), message = FALSE}
# read data file
df.raw.E3 <- read_csv(fn.raw.E3)
str(df.raw.E3)
```

```{r calculate the Z value for RT and clean data (E3)}
# clean and rename the levels of independent variables
df.clean.E3 <- {
  df.raw.E3 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "111_CF_CFS_test" ~ viewing.levels[1],
        Experiment == "111_CF_monocular_test" ~ viewing.levels[2]
      ),
      TrialType = trialtype.levels[1],
      ExpCode = "E3",
      WithCatch = FALSE,
      Response = substring("SD", thisResponse, thisResponse),
      thisResponse = as.character(thisResponse)
    ) %>% 
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    filter(reactionTime > rm.RT) %>% 
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup()  # ungroup the data
}

# head(df.clean.E3)
```


## The composite face task
```{r data frame for CF in E3}
df.clean.cf.E3 <- {
  df.clean.E3 %>% 
    # filter(TrialType == "CF") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E3)
```

```{r check the number of remaining trials E3}
# number of trials in each condition
d.Count.E3 <- {
  df.clean.cf.E3 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.E3 %>%
  spread(Conditions, Count)

rm.count.E3 <- {
  d.Count.E3 %>% 
    filter(Count < max(d.Count.E3$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E3` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.


### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E3)}
# calculate the d'
d.R.E3 <- { # get the hit and correct rejection rates
  df.clean.cf.E3 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>%  # remove Count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E3 <- unique(d.R.E3$Participant[(d.R.E3$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E3 <- unique(d.R.E3$Participant[is.na(d.R.E3$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E3)
rm.E3 <- factor(rmLevels[unique(c(rm.count.E3, rm.nega.E3, rm.missing.E3))], levels = rmLevels)

d.R.E3 <- d.R.E3[!(d.R.E3$Participant %in% rm.E3), ]

# descriptive statistics of d for plotting
desc.d.R.E3 <- {
  d.R.E3 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E3 <- {
  d.R.E3 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```

Participant `r rm.nega.E3` were removed due to at least one of their dprime was not larger than 0.


```{r save data of E3 for analysis in jamovi E3}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E3, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E3, output.d.SPSS, row.names = FALSE)
}
```

#### RainClound plots of d'
```{r rainclound plot of sensitivity E3, warning=FALSE}
knitr::kable(desc.d.R.E3, digits = 4)

d.RainPlot.E3 <- {
  ggplot(data = d.R.E3, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E3, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E3, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 3", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme 
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E3}
d.RainPlot.E3
```

#### Line plots of d'
```{r Plot of d E3}

d.ColuPlot.E3 = {
  ggplot(data = desc.d.R.E3, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 3", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E3
```



### Correct response times
```{r calculate the correct response times for R analysis E3}
cf.rt.R.E3 <- {
  df.clean.cf.E3 %>%
    filter(!(Participant %in% rm.E3)) %>%  # remove participants
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
cf.desc.rt.R.E3 <- {
  cf.rt.R.E3 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
cf.rt.SPSS.E3 <- {
  cf.rt.R.E3 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```


```{r save the RT for R analysis in jomovi E3}
# save the RT for R analysis
if (saveData) {
  # write.csv(cf.rt.R.E3, output.rt.R, row.names = FALSE)
  write.csv(cf.rt.SPSS.E3, output.rt.SPSS, row.names = FALSE)
}

```

#### RainClound plots of RT
```{r rainclound plot of correct response times E3, warning = FALSE}
knitr::kable(cf.desc.rt.R.E3, digits = 4)

rt.RainPlot.E3 <- {
  ggplot(data = cf.rt.R.E3, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = cf.desc.rt.R.E3, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = cf.desc.rt.R.E3, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for Experiment 3", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r display the RainCloud plot for response times E3}
rt.RainPlot.E3
```

#### Line plots of RT
```{r Plot of correct response times E3}

rt.ColuPlot.E3 = {
  ggplot(data = cf.desc.rt.R.E3, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 3", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E3
```


# Experiment 4
```{r information about the data set in E4}
## the filename of the raw data file 
fn.raw.E4 <- file.path(folder.data, "Statistics_n-4_exp-3_2019-02-12-0924.csv")

## input the filename of the output file (.csv)
output.name <- "E4_112"

```

```{r save CSV E4, include = FALSE}

# set the filenames for R and SPSS data format
if (saveData) {
  # output.d.R <- file.path(folder.output, paste0(output.name, "_d_R.csv"))
  output.d.SPSS <- file.path(folder.output, paste0(output.name, "_d_SPSS.csv"))
  # output.rt.R <- file.path(folder.output, paste0(output.name, "_rt_R.csv"))
  output.rt.SPSS <- file.path(folder.output, paste0(output.name, "_rt_SPSS.csv"))
  # output.catch.acc.R <- file.path(folder.output, paste0(output.name, "_catch_acc_R.csv"))
  output.catch.acc.SPSS <- file.path(folder.output, paste0(output.name, "_catch_acc_SPSS.csv"))
  # output.catch.rt.R <- file.path(folder.output, paste0(output.name, "_catch_rt_R.csv"))
  output.catch.rt.SPSS <- file.path(folder.output, paste0(output.name, "_catch_rt_SPSS.csv"))
}

```

The raw data for Experiment 4 was loaded from the file named `r basename(fn.raw.E4)` in the *`r dirname(fn.raw.E4)`/* folder. 

## Tidying up the data
```{r read the raw data file and set the name for output file (E4), message = FALSE}
# read data file
df.raw.E4 <- read_csv(fn.raw.E4)
str(df.raw.E4)
```


```{r calculate the Z value for RT and clean data (E4)}
# clean and rename the levels of independent variables
df.clean.E4 <- {
  df.raw.E4 %>%
    tbl_df() %>%  # change into table data frame format
    mutate(
      Viewing = case_when(  # rename the levels for Experiment
        Experiment == "112_CF_CFS_catch_test" ~ viewing.levels[1],
        Experiment == "112_CF_monocular_catch_test" ~ viewing.levels[2],
        Experiment == "112_catch_test" ~ viewing.levels[3]
      ),
      TrialType = case_when(
        TrialType == "CF" ~ trialtype.levels[1],
        TrialType == "Catch" ~ trialtype.levels[2]
      ),
      ExpCode = "E4",
      WithCatch = TRUE,
      Response = if_else(TrialType == "CF", substring("SD", thisResponse, thisResponse), as.character(thisResponse)),
      thisResponse = as.character(thisResponse)
    ) %>% 
    group_by(Viewing, Participant, TrialType, Congruency, Alignment, SameDifferent, isCorrect) %>% # divide into groups 
    filter(reactionTime > rm.RT) %>% 
    mutate(
      RT.Z = scale(reactionTime), # calculate the Z value for response times within each group
      RT.Within3Z = if_else(RT.Z <= 3 & RT.Z >= -3, 1, if_else(RT.Z < -3 | RT.Z > 3, 0, NaN))
    ) %>%  # if the Z values are between -3 and 3, will be marked as 1. 
    ungroup()  # ungroup the data
}

# head(df.clean.E4)
```


## The composite face task
```{r data frame for CF in E4}
df.clean.cf.E4 <- {
  df.clean.E4 %>% 
    filter(TrialType == "CF") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
      Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
      SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2])
    )
}

head(df.clean.cf.E4)
```

```{r check the number of remaining trials E4 cf}
# number of trials in each condition
d.Count.cf.E4 <- {
  df.clean.cf.E4 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(substr(Viewing, 1,3), substr(Congruency, 1, 1), substr(Alignment,1,1), substr(SameDifferent,1,1), sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.cf.E4 %>%
  spread(Conditions, Count)

rm.count.E4 <- {
  d.Count.cf.E4 %>% 
    filter(Count < max(d.Count.cf.E4$Count) * rm.Count.rate) %$%
    unique(Participant)
}

```
Participant `r rm.count.E4` were removed due to the response times of more than `r (1-rm.Count.rate)*100`% trials were smaller than `r rm.RT*1000`ms in at least one of the conditions.

### Sensitivity d'
```{r calculate the sensitivity d for R analysis (E4)}
# calculate the d'
d.R.E4 <- { # get the hit and correct rejection rates
  df.clean.cf.E4 %>%
    group_by(Viewing, Participant, Congruency, Alignment, SameDifferent) %>%  # divide the data into serveral groups 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% # get accuracy and count for each condition (hit and correct rejection)  
    mutate(Accuracy = if_else(Accuracy == 1, 1 - 0.5/Count, Accuracy)) %>%  # set 1 equals to 1-0.5/n
    select(-Count) %>%  # remove Count
    spread(SameDifferent, Accuracy) %>%  # spread the Accuracy into two columns based on SameDifferent
    mutate(FA = 1 - different,
           Z.hit = qnorm(same),
           Z.FA = qnorm(FA),
           dprime = Z.hit - Z.FA) %>% # get the d prime
    select(Viewing, Participant, Congruency, Alignment, dprime) %>% 
    ungroup()
}

# remove the participants whose dprime were less than 1 in at least one condition
rm.nega.E4 <- unique(d.R.E4$Participant[(d.R.E4$dprime <= 0)]) # participants whose dprime is less than 0 
rm.missing.E4 <- unique(d.R.E4$Participant[is.na(d.R.E4$dprime)]) # dprie is missing

rmLevels = levels(rm.count.E4)
rm.E4 <- factor(rmLevels[unique(c(rm.count.E4, rm.nega.E4, rm.missing.E4))], levels = rmLevels)

d.R.E4 <- d.R.E4[!(d.R.E4$Participant %in% rm.E4), ]

# descriptive statistics of d for plotting
desc.d.R.E4 <- {
  d.R.E4 %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(dprime), N = n(), SD = sd(dprime), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(dprime), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# d for SPSS sytle analysis
d.SPSS.E4 <- {
  d.R.E4 %>%
    ungroup() %>%  # ungroup the data.d.r 
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>% # combine all the levels together
    select(Participant, dprime, Conditions) %>% # delete the Independet Variables
    spread(Conditions, dprime)
}

```
Participant `r rm.nega.E4` were removed due to at least one of their dprime was not larger than 0.

Participant `r rm.missing.E4` were removed due to at least one of their dprime was missing.


```{r save data of E4 for analysis in jamovi E4}
# save the d' for R analysis
if (saveData) {
  # write.csv(d.R.E4, output.d.R, row.names = FALSE)
  write.csv(d.SPSS.E4, output.d.SPSS, row.names = FALSE)
}
```


#### RainClound plots of d'
```{r rainclound plot of sensitivity E4, warning=FALSE}
knitr::kable(desc.d.R.E4, digits = 4)

d.RainPlot.E4 <- {
  ggplot(data = d.R.E4, aes(y = dprime, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = dprime, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = dprime), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = desc.d.R.E4, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = desc.d.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Sensitivity d' for Experiment 4", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme 
}

```

&nbsp;

```{r display the RainCloud plot for sensitivity (d) E4}
d.RainPlot.E4
```


#### Line plots of d'
```{r Plot of d E4}

d.ColuPlot.E4 = {
  ggplot(data = desc.d.R.E4, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 4.5)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Sensitivity for Experiment 4", x = "Viewing Conditions", y = "Sensitivity", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "***", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

d.ColuPlot.E4
```



### Correct response times
```{r calculate the correct response times for R analysis E4}
cf.rt.R.E4 <- {
  df.clean.cf.E4 %>%
    filter(!(Participant %in% rm.E4)) %>%  # remove participants
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Congruency, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}

# descriptive statistics of RT for plotting
cf.desc.rt.R.E4 <- {
  cf.rt.R.E4 %>% 
    select(-Count) %>% 
    group_by(Viewing, Congruency, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
cf.rt.SPSS.E4 <- {
  cf.rt.R.E4 %>%
    mutate(Conditions = paste(Viewing, Congruency, Alignment, sep = ".")) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```


```{r save the RT for R analysis in jomovi E4}
# save the RT for R analysis
if (saveData) {
  # write.csv(cf.rt.R.E4, output.rt.R, row.names = FALSE)
  write.csv(cf.rt.SPSS.E4, output.rt.SPSS, row.names = FALSE)
}

```


#### RainClound plots of RT
```{r rainclound plot of correct response times E4, warning = FALSE}
knitr::kable(cf.desc.rt.R.E4, digits = 4)

rt.RainPlot.E4 <- {
  ggplot(data = cf.rt.R.E4, aes(y = RT, x = Alignment, fill = Congruency)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(aes(y = RT, color = Congruency), position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(aes(y = RT), width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = cf.desc.rt.R.E4, aes(y = Mean, x = Alignment, color = Congruency), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = cf.desc.rt.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times for Experiment 4", x = "Alignment", y = "Response Times (ms)", fill = "Congruency", color = "Congruency") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r display the RainCloud plot for response times E4}
rt.RainPlot.E4
```

#### Line plots of RT
```{r Plot of correct response times E4}

rt.ColuPlot.E4 = {
  ggplot(data = cf.desc.rt.R.E4, aes(y = Mean, x = Alignment, color = Congruency, group = Congruency)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_point() +
    geom_line() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    coord_cartesian(ylim = c(0, 1100)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    facet_grid(. ~ Viewing, switch = "both") +
    labs(title = "Correct Response Times for Experiment 4", x = "Viewing Conditions", y = "Response Times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_text(label = c("", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 30, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

rt.ColuPlot.E4
```

## Catch trials
```{r data frame for Cacth trials in E4}
df.clean.catch.E4 <- {
  df.clean.E4 %>% 
    filter(TrialType == "catch") %>% # only keep the trials for composite face task
    mutate(
      Participant = as.factor(Participant),
      Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2], "CatchOnly" = viewing.levels[3]),
      Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2])
    ) %>% 
    filter(!(Participant %in% rm.E4))  # remove participants
}

df.clean.catch.E4
```


```{r check the number of remaining trials E4 catch}
# number of trials in each condition
d.Count.catch.E4 <- {
  df.clean.catch.E4 %>%
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(Count = n()) %>% 
    mutate(Conditions = paste(Viewing, Alignment, sep = ".")) %>% 
    ungroup() %>% 
    select(Participant, Conditions, Count) 
}

d.Count.catch.E4 %>%
  spread(Conditions, Count)

```


### Accuracy for catch trials
```{r accuracy for catch trials E4}
catch.acc.R.E4 <- {
  df.clean.catch.E4 %>%
    group_by(Viewing, Participant, Alignment) %>% 
    summarize(Accuracy = mean(isCorrect), Count = n()) %>% 
    ungroup()
}

catch.desc.acc.R.E4 <- {
  catch.acc.R.E4 %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(Accuracy), N = n(), SD = sd(Accuracy), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(Accuracy), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

catch.acc.SPSS.E4 <- {
  catch.acc.R.E4 %>% 
    mutate(Condition = factor(paste(Viewing, Alignment, sep = "."), levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>% 
    select(Participant, Condition, Accuracy) %>%
    spread(Condition, Accuracy)
}


```

```{r save the acc of catch trials in jamovi E4}
# save the acc of catch trials in jamovi E4
if (saveData) {
  # write.csv(catch.acc.R.E4, output.catch.acc.R, row.names = FALSE)
  write.csv(catch.acc.SPSS.E4, output.catch.acc.SPSS, row.names = FALSE)
}
```


#### RainClound plot of accuracy
```{r rainclound plot of accuracy for catch E4, warning=FALSE}
knitr::kable(catch.desc.acc.R.E4, digits = 4)

catch.acc.RainPlot.E4 <- {
  ggplot(data = catch.acc.R.E4, aes(y = Accuracy, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15, height = 0), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.acc.R.E4, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.acc.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Accuracy for Catch Trials in Experiment 4", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises and the legend
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

```{r rainclound plot of accuracy for catch trials E4}
catch.acc.RainPlot.E4
```


#### Column plots of accuracy
```{r Plot of accuracy for catch trials E4}

catch.acc.ColuPlot.E4 = {
  ggplot(data = catch.desc.acc.R.E4, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 1.05)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 4", x = "Viewing Conditions", y = "Accuracy") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "***", "***"), color = "red", size = 6, nudge_y = 0.1, nudge_x = 0) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E4
```

### Response Times
```{r calculate the correct response times of catch trials for R analysis E4}
catch.rt.R.E4 <- {
  df.clean.catch.E4 %>%
    filter(reactionTime <= 10) %>%  # remove the response times which are longer than 10s
    filter(RT.Within3Z == 1)  %>%  # only keep the RT within 3 Z
    # filter(isCorrect == 1)  %>%  # only keep the correct correct
    group_by(Viewing, Participant, Alignment) %>%  # divide the data into serveral groups 
    summarize(RT = mean(reactionTime) * 1000, Count = n()) %>% # get RT and count for each condition
    ungroup()
}


# descriptive statistics of RT for plotting
catch.desc.rt.R.E4 <- {
  catch.rt.R.E4 %>% 
    select(-Count) %>% 
    group_by(Viewing, Alignment) %>% 
    summarize(Mean = mean(RT), N = n(), SD = sd(RT), SE = SD/sqrt(N), SE.hi = Mean + SE, SE.lo = Mean - SE, CI = SE * qt(0.975,N), Median = median(RT), Lower = Mean - SD, Upper = Mean + SD) %>% 
    ungroup()
}

# RT for SPSS sytle analysis
catch.rt.SPSS.E4 <- {
  catch.rt.R.E4 %>%
    mutate(Conditions = factor(paste(Viewing, Alignment, sep = ".") , levels = c("CFS.aligned", "CFS.misaligned", "monocular.aligned", "monocular.misaligned", "CatchOnly.aligned", "CatchOnly.misaligned"))) %>%
    select(Participant, Conditions, RT) %>% 
    spread(Conditions, RT)
}

```

```{r save the RT for R analysis catch trials in E4}
# save the RT for R analysis
if (saveData) {
  # write.csv(catch.rt.R.E4, output.catch.rt.R, row.names = FALSE)
  write.csv(catch.rt.SPSS.E4, output.catch.rt.SPSS, row.names = FALSE)
}
```


#### RainClound plot of response times
```{r rainclound plot of response times for catch trials E4, warning=FALSE}
knitr::kable(catch.desc.rt.R.E4, digits = 4)

catch.rt.RainPlot.E4 <- {
  ggplot(data = catch.rt.R.E4, aes(y = RT, x = Alignment)) + 
    geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .7) +
    geom_point(position = position_jitter(width = .15), size = .5, alpha = .8) +
    geom_boxplot(width = .2, outlier.shape = NA, alpha = .7) +
    geom_point(data = catch.desc.rt.R.E4, aes(y = Mean, x = Alignment), position = position_nudge(x = 0.3), size = 2.5) +
    geom_errorbar(data = catch.desc.rt.R.E4, aes(y = Mean, ymin = Lower, ymax = Upper), position = position_nudge(x = 0.3), width = 0) +
    facet_grid(. ~ Viewing, switch = "both") +
    # scale_colour_grey() + # start = .1, end = .6, color for the contour
    # scale_fill_grey() + # start = .3, end = .6, color for the fill
    # scale_color_brewer(palette = "Set1") +
    # scale_fill_brewer(palette = "Set1") +
    labs(title = "Correct Response Times of Catch Trials for Experiment 4", x = "Alignment", y = "Response Times (ms)") +  # set the names for main, x and y axises and the legend
    # coord_cartesian(ylim = c(0, 6)) +  # set the limit for y axis
    # scale_y_continuous(expand = c(0, 0)) +  # remove the space between columns and x axis
    # geom_hline(yintercept = 0, linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    theme_bw() + # the backgroud color
    plot_theme
}

```

&nbsp;

```{r display the RainCloud plot of response times for catch trials E4}
catch.rt.RainPlot.E4
```

#### Column plot of response times
```{r Plot of response times for catch trials E4}

catch.acc.ColuPlot.E4 = {
  ggplot(data = catch.desc.rt.R.E4, aes(y = Mean, x = Alignment)) +  # set the data, varialbes for x and y axises, and the variable for dividing data
    geom_col() +  # position = "dodge", alpha = .7
    geom_errorbar(mapping = aes(ymin = SE.lo, ymax = SE.hi), linetype = 1,  # set the error bar
                  show.legend = FALSE, width = 0.25, alpha = .5) + # ,                   position = position_dodge(width=0.9)
    facet_grid(. ~ Viewing, switch = "both") +
    coord_cartesian(ylim = c(0, 3200)) +  # set the limit for y axis
    scale_y_continuous(expand= c(0, 0)) +  # remove the space between columns and x axis
    labs(title = "Accuracy of Catch Trials in Experiment 4", x = "Viewing Conditions", y = "Response Times (ms)") +  # set the names for main, x and y axises
    scale_fill_grey() +  # set the color for columns
    # geom_hline(yintercept = c(0.5, 1), linetype = 5, alpha = 0.5) + # add the line for 0.5 and 1 (y)
    geom_text(label = c("", "", "", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
    theme_bw() +
    plot_theme
}

catch.acc.ColuPlot.E4
```


# Analysis for all the four experiemnts
```{r load libraries for lmm}
# load libraries for lmm
library(lme4)
library(lmerTest)

source(file.path(folder.R, "get_pars.R"))
```

```{r combine the data from the four experiments}

df.all <- bind_rows(list(df.clean.E1, df.clean.E2,  df.clean.E3, df.clean.E4))
head(df.all)
```

## The composite face task
```{r tidy up the dataframe for the composite face task}
rmParticipant <- c(as.character(rm.E1), as.character(rm.E2), as.character(rm.E3), as.character(rm.E4))

rmParticipant

df.cf.all <- {
  df.all %>% 
    filter(TrialType == "CF") %>% 
    filter(!(Participant %in% rmParticipant)) %>% 
    mutate(Participant = as.factor(Participant),
           Viewing = recode_factor(Viewing, "CFS" = viewing.levels[1], "monocular" = viewing.levels[2]),
           Congruency = recode_factor(Congruency, "C" = congruency.levels[1], "I" = congruency.levels[2]), # rename the levels for Congruency
           Alignment = recode_factor(Alignment, "A" = alignment.levels[1], "M" = alignment.levels[2]),
           SameDifferent = recode_factor(SameDifferent, "S" = sameDifferent.levels[1], "D" = sameDifferent.levels[2]),
           FaceGroup = as.factor(FaceGroup)) %>% 
    filter(SameDifferent == "same") %>% # only keep the data for trials
    select(Viewing, Participant, Congruency, Alignment, FaceGroup, WithCatch, isCorrect, reactionTime, ExpCode, RT.Z)
}

head(df.cf.all)

```


```{r manually set the dummy coding for random effects}
# manually set the dummy coding for random effects
df.cf.all %<>% dummy_coding_P101()

if (saveData) {
  save(df.cf.all, file = file.path(folder.nesi, "P101_cf_clean.RData"))
  # write_csv(df.cf.all, file.path(folder.nesi, "P101_cf_clean.csv"))
}
```


### Responses
#### Logit mixed model
##### Build up
```{r}

glmm.rsp1 <- glmer(isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                        (1 | Participant), 
                      data = df.cf.all,
                      family = "binomial",
                      # verbose = TRUE,
                      control = glmerControl(optCtrl = list(maxfun = 1e6)))

glmm.rsp2 <- re_fit(glmm.rsp1)

print(summary(glmm.rsp2), corr = FALSE)

```

```{r}
glmm.rsp3 <- update(glmm.rsp2,
                    formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                        (1 + View_D | Participant),
                    start = NULL)

glmm.rsp4 <- re_fit(glmm.rsp3)

anova(glmm.rsp4, glmm.rsp2)
```

```{r}
glmm.rsp5 <- update(glmm.rsp4,
                    formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                        (1 + View_D + Con_D | Participant),
                    start = NULL)

glmm.rsp6 <- re_fit(glmm.rsp5)

anova(glmm.rsp6, glmm.rsp4)
```

```{r}
glmm.rsp7 <- update(glmm.rsp4,
                    formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                        (1 + View_D + Ali_D | Participant),
                    start = NULL)

glmm.rsp8 <- re_fit(glmm.rsp7)

anova(glmm.rsp6, glmm.rsp4)
```

```{r}
glmm.rsp9 <- update(glmm.rsp4,
                    formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                        (1 + Con_D + Ali_D | Participant),
                    start = NULL)

glmm.rsp10 <- re_fit(glmm.rsp9)

anova(glmm.rsp10, glmm.rsp4)
```


```{r}
glmm.rsp11 <- update(glmm.rsp4,
                    formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                        (1 + View_D + Con_D + Ali_D | Participant),
                    start = NULL)

glmm.rsp12 <- re_fit(glmm.rsp11)

anova(glmm.rsp10, glmm.rsp4)
```


##### Maximal model
```{r maximal model for responses}
# maximal model for responses
file.max.resp <- file.path(folder.nesi, "P101_resp_glmm_max.RData")

if (!file.exists(file.max.resp)) {

  glmm.max.resp <- glmer(isCorrect ~ Viewing * Congruency * Alignment + ExpCode + 
                          (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali + View_Con_Ali | Participant), 
                        data = df.cf.all,
                        family = "binomial",
                        # verbose = TRUE,
                        control = glmerControl(optCtrl = list(maxfun = 1e6)))

  glmm.max1.resp <- re_fit(glmm.max.resp)
  
} else {
  load(file.max.resp)
}

print(summary(glmm.max.resp), corr = FALSE)
```

```{r maximal model 2 for responses}
# maximal model 2 for responses (starting with the parameters from maximal model)

# print(summary(glmm.max1.resp), corr = FALSE)

```

##### Zero-correlation-parameter model
```{r zcp model for responses}
# zero-correlation-parameter model for responses
file.zcp.resp <- file.path(folder.nesi, "P101_resp_glmm_zcp.RData")

if (!file.exists(file.zcp.resp)) {
  glmm.zcp.resp <- update(glmm.max.resp,
                         formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode +
                           (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali + View_Con_Ali || Participant),
                         verbose = FALSE)
  
  glmm.zcp1.resp <- re_fit(glmm.zcp.resp)

} else {
  load(file.zcp.resp)
}

print(summary(glmm.zcp1.resp), corr = FALSE)
```

```{r}
summary(rePCA(glmm.zcp1.resp))
```


##### Reduced model
```{r reduced model for responses}
# reduced model for responses
file.rdc.resp <- file.path(folder.nesi, "P101_resp_glmm_rdc.RData")

if (!file.exists(file.rdc.resp)) {
  glmm.rdc.resp <- update(glmm.zcp.resp,
                         formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode +
                           (1 + View_D + Con_D + View_Con + View_Ali + Con_Ali || Participant),
                         verbose = FALSE)

  save(glmm.rdc.resp, file = file.rdc.resp)
} else {
  load(file.rdc.resp)
}

print(summary(glmm.rdc.resp), corr = FALSE)

```

```{r}
anova(glmm.rdc.resp, glmm.zcp1.resp)
```


##### Extended model
```{r extended model for respuarcy}
# extended model for respuarcy
file.etd.resp <- file.path(folder.nesi, "P101_resp_glmm_etd.RData")

if (!file.exists(file.etd.resp)) {
  glmm.etd.resp <- update(glmm.rdc.resp,
                         formula = isCorrect ~ Viewing * Congruency * Alignment + ExpCode +
                           (1 + View_D + Con_D + View_Con + View_Ali + Con_Ali | Participant),
                         verbose = FALSE)

} else {
  load(file.etd.resp)
}

print(summary(glmm.etd.resp), corr = FALSE)

```


```{r}
file.etd.resp.allFit <- file.path(folder.nesi, "P101_resp_glmm_etd_allFit.RData")

if (!file.exists(file.etd.resp.allFit)) {
  glmm.etd0.resp <- glmer(isCorrect ~ Viewing * Congruency * Alignment + ExpCode +
                            (1 + View_D + Con_D + View_Con + View_Ali + Con_Ali | Participant),
                          data = df.cf.all,
                          family = "binomial",
                          verbose = TRUE
  )
  
  glmm.etd.resp.allFit <- allFit(glmm.etd0.resp,
                                 control = glmerControl(optCtrl = list(maxfun = 1e6)))
  
} else {
  load(file.etd.resp.allFit)
}

# print(summary(glmm.etd.resp.allFit), corr = FALSE)

```


##### Optimal model
```{r}


```



#### Estimated marginal means
```{r}
emm.resp <- emmeans(glmm.opt.resp, ~ Alignment | c(Congruency, Viewing))

data.frame(summary(emm.resp)) %>% 
  select(Viewing, Congruency, Alignment, everything())

```


#### Plots 
```{r}
emmip(glmm.opt.resp, Congruency ~ Alignment | Viewing, CIs = TRUE)


```



#### Contrasts
```{r}
contrast(emm.resp, "pairwise", simple = "each", combine = TRUE, adjust = "bonferroni")
```

```{r}
contrast(emm.resp, interaction = "pairwise", by = "Viewing")
```


### Sensitivity d'
```{r}
# combine d' data
d.R.E1 %<>% mutate(ExpCode = "E1", isCatch = 0, Participant = as.character(Participant))
d.R.E2 %<>% mutate(ExpCode = "E2", isCatch = 1, Participant = as.character(Participant))
d.R.E3 %<>% mutate(ExpCode = "E3", isCatch = 0, Participant = as.character(Participant))
d.R.E4 %<>% mutate(ExpCode = "E4", isCatch = 1, Participant = as.character(Participant))

d.R.all <- {
    bind_rows(d.R.E1, d.R.E2, d.R.E3, d.R.E4)
}

d.R.all <- dummy_coding_P101(d.R.all)

```

#### The maximal model
```{r}
lmm.max.d <- lmer(dprime ~ Viewing * Congruency * Alignment + ExpCode +
                    (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali | Participant), 
                  data = d.R.all,
                  REML = FALSE)

print(summary(lmm.max.d), corr = FALSE)
```

#### The zero-correlation-parameter model
```{r}
lmm.zcp.d <- update(lmm.max.d,
                    formula = dprime ~ Viewing * Congruency * Alignment + ExpCode +
                    (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali || Participant))

print(summary(lmm.zcp.d), corr = FALSE)
```


#### The reduced model
```{r}
summary(rePCA(lmm.zcp.d))
```

```{r}
lmm.rdc.d <- update(lmm.zcp.d,
                    formula = dprime ~ Viewing * Congruency * Alignment + ExpCode +
                      (1 + View_D + Con_D + Con_Ali || Participant))

print(summary(lmm.rdc.d), corr = FALSE)
```


```{r}
lmm.rdc1.d <- update(lmm.rdc.d, 
                     formula = dprime ~ Viewing * Congruency * Alignment + ExpCode +
                       (1 + View_D + Con_D + Con_Ali + View_Con_Ali || Participant))

print(summary(lmm.rdc1.d), corr = FALSE)
```

#### The extended model
```{r}
lmm.etd.d <- update(lmm.rdc.d,
                    formula = dprime ~ Viewing * Congruency * Alignment + ExpCode +
                    (1 + View_D + Con_D + Con_Ali | Participant))

print(summary(lmm.etd.d), corr = FALSE)
```

```{r}
anova(lmm.etd.d, lmm.rdc.d)
```

#### The optimal model
```{r}
lmm.opt.d <- update(lmm.etd.d,
                    REML = TRUE)

summary(lmm.opt.d)
```


#### Disgnostic plots
```{r}
qqplot_lmer(lmm.opt.d)
```

#### Estimated marginal means

```{r}
emm.d.all <- emmeans(lmm.opt.d, ~ Alignment | c(Congruency, Viewing))
data.frame(summary(emm.d.all)) %>% 
  select(Viewing, Congruency, Alignment, everything())
```


```{r}
emmip(emm.d.all, Congruency ~ Alignment | Viewing, CIs = TRUE)

```


```{r}
contrast(emm.d.all, "pairwise", simple = "each", combine = TRUE, adjust = "bonferroni")
```



### Correct response times
```{r}
df.cf.rt <- {
  df.cf.all %>% 
    filter(isCorrect == 1) %>% 
    mutate(RT = if_else(ExpCode == "E1", reactionTime * 1000 + 300, reactionTime * 1000))
}

```


#### Linear mixed model
##### The maximal model
```{r maximal model for correct RT }
# maximal model for correct RT
file.max.rt <- file.path(folder.nesi, "P101_rt_lmm_max.RData")

if (!file.exists(file.max.rt)) {
  lmm.max.rt <- lmer(reactionTime ~ Viewing * Congruency * Alignment + ExpCode +
                       (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali + View_Con_Ali | Participant),
                     data = df.cf.rt,
                     REML = FALSE,
                     # verbose = TRUE,
                     control = lmerControl(optCtrl = list(maxfun = 1e6))
  )
    save(lmm.max.rt, file = file.max.rt)
} else {
    load(file.max.rt)
}

print(summary(lmm.max.rt), corr = FALSE)
```

##### The zcp model
```{r zcp model for correct RT }
# zcp model for correct RT
file.zcp.rt <- file.path(folder.nesi, "P101_rt_lmm_zcp.RData")

if (!file.exists(file.zcp.rt)) {
  lmm.zcp.rt <- update(lmm.max.rt,
                       formula = reactionTime ~ Viewing * Congruency * Alignment + ExpCode +
                         (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali + View_Con_Ali || Participant))
} else {
    load(file.zcp.rt)
}

print(summary(lmm.zcp.rt), corr = FALSE)
```

##### The reduced model
```{r}

# zcp model for correct RT
file.zcp.rt.step <- file.path(folder.nesi, "P101_rt_lmm_zcp_step.RData")

if (!file.exists(file.zcp.rt.step)) {
  lmm.zcp.rt.step <- step(lmm.zcp.rt, reduce.fixed = FALSE)
} else {
    load(file.zcp.rt.step)
}

lmm.zcp.rt.step

```


```{r}
lmm.rdc.rt <- get_model(lmm.zcp.rt.step)

print(summary(lmm.rdc.rt), corr = FALSE)
```

##### The extended model
```{r etd model for correct RT }
# extended model for correct RT
file.etd.rt <- file.path(folder.nesi, "P101_rt_lmm_etd.RData")

if (!file.exists(file.etd.rt)) {
  lmm.etd.rt <- update(lmm.zcp.rt,
                       formula = reactionTime ~ Viewing * Congruency * Alignment + ExpCode +
                         (1 + View_D | Participant),
                       verbose = FALSE)
} else {
    load(file.etd.rt)
}

print(summary(lmm.etd.rt), corr = FALSE)
```

```{r}
anova(lmm.etd.rt, lmm.rdc.rt)
```

##### The optimal model
```{r}
lmm.opt.rt <- update(lmm.etd.rt,
                     REML = TRUE,
                     verbose = FALSE)

summary(lmm.opt.rt)

```


##### Check the residuals
```{r}
qqnorm(residuals(lmm.opt.rt))
```

```{r}
qqplot_lmer(lmm.opt.rt)
```
Generalized linear mixed (log) model has to be used for RT. 


#### Log mixed model
##### Maximal model
```{r maximal model for correct RT }
# maximal model for correct RT
file.max.rt <- file.path(folder.nesi, "P101_rt_glmm_max.RData")

if (!file.exists(file.max.rt)) {
  glmm.max.rt <- glmer(reactionTime ~ Viewing * Congruency * Alignment + ExpCode +
                         (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali + View_Con_Ali | Participant),
                       data = df.cf.rt,
                       family = "poisson",
                       # verbose = TRUE,
                       control = glmerControl(optCtrl = list(maxfun = 1e6))
  )
  
  save(glmm.max.rt, file = file.max.rt)
} else {
  load(file.max.rt)
}

print(summary(lmm.max.rt), corr = FALSE)
```

##### The zero-correlation-parameter model
```{r zcp model for correct RT }
# zcp model for correct RT
file.zcp.rt <- file.path(folder.nesi, "P101_rt_glmm_zcp.RData")

if (!file.exists(file.zcp.rt)) {
    glmm.zcp.rt <- glmer(reactionTime ~ Viewing * Congruency * Alignment + ExpCode +
                              (1 + View_D + Con_D + Ali_D + View_Con + View_Ali + Con_Ali + View_Con_Ali || Participant),
                          data = df.cf.rt,
                          family = "poisson",
                          # verbose = TRUE,
                          control = glmerControl(optCtrl = list(maxfun = 1e6))
    )

} else {
    load(file.zcp.rt)
}

print(summary(lmm.zcp.rt), corr = FALSE)
```

# Versions of Packages Used
```{r versions}
rstudioapi::versionInfo()
sessionInfo()
```

